{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/WtkZPXPnFjItkfw7HsxU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f9ab40aba6644a6989feab7c2d045aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45e65136c9f34f7e99aa0c82eefff051",
              "IPY_MODEL_9f84a740b1d14f759c1065fae3b2b302",
              "IPY_MODEL_de8a4115484a457584125dc26e2e555c"
            ],
            "layout": "IPY_MODEL_f27dff0454ea4b358655da563cf2a225"
          }
        },
        "45e65136c9f34f7e99aa0c82eefff051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8be98ba442f4bed8031f684ef40ce47",
            "placeholder": "​",
            "style": "IPY_MODEL_bc865a1307384ccabe0f9b4fa2e27ed0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9f84a740b1d14f759c1065fae3b2b302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23e4a57b8c1846b2a28a461f4a5c87b3",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae7e8c18e00b4dfcbfda2a7cf98be4cd",
            "value": 8
          }
        },
        "de8a4115484a457584125dc26e2e555c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51fbab10bbd04321a5b7704d2bdebfc0",
            "placeholder": "​",
            "style": "IPY_MODEL_b7aa272eac9e4c6a9f36c569458b449c",
            "value": " 8/8 [01:18&lt;00:00,  8.39s/it]"
          }
        },
        "f27dff0454ea4b358655da563cf2a225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8be98ba442f4bed8031f684ef40ce47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc865a1307384ccabe0f9b4fa2e27ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23e4a57b8c1846b2a28a461f4a5c87b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7e8c18e00b4dfcbfda2a7cf98be4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51fbab10bbd04321a5b7704d2bdebfc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7aa272eac9e4c6a9f36c569458b449c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mananuppadhyay/QNA-Mistral-Langchain/blob/main/RAG_using_Mistral_and_Langchain_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to run the notebook:\n",
        "1. Add the path to the pdf file after uploading it to the colab environment\n",
        "2. Run all the cells, and the last block has the option for user input query and answer for the same.\n",
        "\n",
        "\n",
        "Some details:\n",
        "LLM used: Mistral 7B (sharded version)\n",
        "Langchain\n",
        "Vector Database: QDrant\n",
        "\n",
        "By: Manan Uppadhyay"
      ],
      "metadata": {
        "id": "G8EgLkhZ6IHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give the path to your pdf file"
      ],
      "metadata": {
        "id": "zXRoMTahTffi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file=\"/content/Assignment 2_Group 5.pdf\""
      ],
      "metadata": {
        "id": "SWLxQNxRTfDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "np9iSv77WaYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U einops\n",
        "!pip install -q -U safetensors\n",
        "#!pip install -q -U torch\n",
        "!pip install -q -U xformers\n",
        "!pip install -q -U langchain\n",
        "!pip install -q -U ctransformers[cuda]\n",
        "!pip install qdrant_client\n",
        "!pip install sentence-transformers\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "9YxRb-nz5ZRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from qdrant_client import QdrantClient\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Qdrant\n",
        "\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "import PyPDF2\n",
        "from langchain.schema.document import Document\n"
      ],
      "metadata": {
        "id": "fObnx7AHKo-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "aV_Z1eqS8zqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")"
      ],
      "metadata": {
        "id": "kMe9vYe_86QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Mistral 7B model and creating the pipeline for the task"
      ],
      "metadata": {
        "id": "bssk98KkW9Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"filipealmeida/Mistral-7B-Instruct-v0.1-sharded\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
        "                                             device_map='auto',\n",
        "                                             torch_dtype=torch.float16,\n",
        "                                             load_in_4bit=True,\n",
        "                                             bnb_4bit_quant_type=\"nf4\",\n",
        "                                             bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "\n",
        "pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        use_cache=True,\n",
        "        device_map=\"auto\",\n",
        "        max_length=600,\n",
        "        do_sample=True,\n",
        "        top_k=5,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipeline)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5f9ab40aba6644a6989feab7c2d045aa",
            "45e65136c9f34f7e99aa0c82eefff051",
            "9f84a740b1d14f759c1065fae3b2b302",
            "de8a4115484a457584125dc26e2e555c",
            "f27dff0454ea4b358655da563cf2a225",
            "c8be98ba442f4bed8031f684ef40ce47",
            "bc865a1307384ccabe0f9b4fa2e27ed0",
            "23e4a57b8c1846b2a28a461f4a5c87b3",
            "ae7e8c18e00b4dfcbfda2a7cf98be4cd",
            "51fbab10bbd04321a5b7704d2bdebfc0",
            "b7aa272eac9e4c6a9f36c569458b449c"
          ]
        },
        "id": "KKEtk7gM87rP",
        "outputId": "bd9bf2e5-8e86-4dd6-b946-a3325ffe6cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f9ab40aba6644a6989feab7c2d045aa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A sample template, question and context to get a response"
      ],
      "metadata": {
        "id": "aG6YIR81XEqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"<s>[INST] You are a helpful, respectful and honest assistant. Answer exactly in few words from the context\n",
        "Answer the question below from context below :\n",
        "{context}\n",
        "{question} [/INST] </s>\n",
        "\"\"\"\n",
        "question_p = \"\"\"Which companies announced their mergers\"\"\"\n",
        "context_p = \"\"\" In a landmark fusion of tech titans, Cybervine and QuantumNet announced their merger today, promising to redefine the digital frontier with their combined innovation powerhouse, now known as CyberQuantum.\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\",\"context\"])\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "response = llm_chain.run({\"question\":question_p,\"context\":context_p})\n",
        "response\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GYUCLaoz8-lp",
        "outputId": "ba1e3b78-53cf-4dfd-89c5-34d317e077fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cybervine and QuantumNet announced their merger and formed CyberQuantum.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code to get the pdf file, chunk it and store it in a vector DB (Qdrant) to retrieve it while answering the queries"
      ],
      "metadata": {
        "id": "Xl0eoQj7XIJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pdf_content(file_path):\n",
        "    pdf_file_obj = open(file_path, 'rb')\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file_obj)\n",
        "    num_pages = len(pdf_reader.pages)\n",
        "    page_content = \"\"\n",
        "    for page in range(num_pages):\n",
        "        page_obj = pdf_reader.pages[page]\n",
        "        page_content += page_obj.extract_text()\n",
        "    pdf_file_obj.close()\n",
        "    return page_content\n",
        "\n",
        "pdf_content = get_pdf_content(pdf_file)\n",
        "\n",
        "documents = [Document(page_content=pdf_content, metadata={\"source\": \"local\"})]\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
        "\n",
        "\n",
        "#Use Qdrant as the vector storage\n",
        "vectordb = Qdrant.from_documents(documents=all_splits, embedding=embeddings, location=\":memory:\",\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"my_documents\",\n",
        ")\n",
        "\n",
        "retriever = vectordb.as_retriever()\n",
        "\n",
        "\n",
        "#Retrieval using LLM\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    verbose=True\n",
        ")\n",
        "def run_my_rag(qa):\n",
        "    query = input(\"Please enter your query: \")\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    result = qa.run(query)\n",
        "    print(\"\\nResult: \", result)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OylLRa8tKJyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enter your query after running this cell:"
      ],
      "metadata": {
        "id": "6vT2No4oW3jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_my_rag(qa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atg8GFjsQ2kQ",
        "outputId": "8c1b0078-c4db-4046-9cae-38add14d2839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your query: What is transnational crime?\n",
            "Query: What is transnational crime?\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Result:   Transnational crime refers to crimes that originated in one or multiple states and impact multiple states. It could involve drug trafficking, human trafficking, smuggling of migrants, illicit trading in firearms, trafficking in natural resources, the illegal trade in wildlife, the sale of fraudulent medicines, or cybercrime. Transnational crime is influenced by cultural and technological globalization and can involve local gangs and organizations that have far-reaching impacts or the creation of large-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VcGskeR1YHWF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}